{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import cv2\n","from tqdm.notebook import tqdm\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# read data\n","data_path = \"../input/cassava-leaf-disease-classification\"\n","train_img_path = os.path.join(data_path, \"train_images\")\n","train_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# EDA\n","print(\"Total Number of Train： {}\".format(len(train_df)))\n","print()\n","print(\"Each Ratio of Train data:\")\n","print(train_df['label'].value_counts()/len(train_df))\n","(train_df['label'].value_counts()/len(train_df)).plot(kind='bar')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_images(df, data_img_path, figsize=(30,20)):\n","    fig = plt.figure(figsize=figsize)\n","    len_train = len(train_df[\"label\"].unique())\n","    for i in range(len_train):\n","        ax = fig.add_subplot(len_train, 1, i+1)\n","        sample = df[df['label']==i]['image_id'].sample().reset_index(drop=True)\n","        sample_img_path = os.path.join(data_img_path, sample.iloc[0])\n","        img = cv2.imread(sample_img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        plt.imshow(img)\n","        plt.title(\"Label: {}, Shape: {}\".format(i, img.shape))\n","    \n","    plt.show()\n","    \n","plot_images(train_df, train_img_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create Dataset and Transform\n","class CassavaDataset(Dataset):\n","    def __init__(self, df:pd.DataFrame, data_img_path:str, phase:str='train', transform=None):\n","        self.df = df\n","        self.data_img_path = data_img_path\n","        self.transform = transform\n","        self.phase = phase\n","        \n","    def __getitem__(self, idx):\n","        sample = self.df['image_id'].iloc[idx]\n","        img = cv2.imread(os.path.join(self.data_img_path, sample))\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        \n","        if self.transform:\n","            img = self.transform(img, self.phase)\n","            \n","        if self.phase=='test':\n","            return img\n","        \n","        label = self.df['label'].iloc[idx]\n","        \n","        return img, label\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","class Transform(object):\n","    def __init__(self, resize:int, mean:list, std:list, crop_size:int):\n","        self.transform = {\n","            'train':A.Compose([\n","                A.Resize(resize, resize),\n","                A.RandomCrop(height=crop_size, width=crop_size),\n","                A.Normalize(mean, std),\n","                A.HorizontalFlip(p=0.5),\n","                A.VerticalFlip(p=0.5),\n","                A.ShiftScaleRotate(p=0.5),\n","                ToTensorV2()\n","            ]),\n","            'val':A.Compose([\n","                A.Resize(resize, resize),\n","                A.CenterCrop(crop_size, crop_size),\n","                A.Normalize(mean, std),\n","                ToTensorV2()\n","            ]),\n","            'test':A.Compose([\n","                A.Resize(resize, resize),\n","                A.CenterCrop(crop_size, crop_size),\n","                A.Normalize(mean, std),\n","                ToTensorV2()\n","            ]),\n","        }\n","    \n","    def __call__(self, img, phase):\n","        return self.transform[phase](image=img)['image']\n","    \n","resize = 256\n","crop_size = 224\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","transform = Transform(resize, mean, std, crop_size)\n","\n","# test dataset and transform\n","dataset = CassavaDataset(train_df, train_img_path, 'train', transform)\n","dataloader = DataLoader(dataset, shuffle=True, batch_size=1, num_workers=2)\n","iterator = dataloader.__iter__()\n","img, label = next(iterator)\n","plt.imshow(img.numpy().transpose(2,3,1,0).reshape(crop_size, crop_size, 3))\n","plt.title(\"Dataset and Transform Test, Label: {}\".format(label))\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create model\n","def conv3x3(in_channels, out_channels, stride=1, groups=1):\n","    return nn.Conv2d(\n","        in_channels, out_channels, kernel_size=3, stride=stride, padding=1, groups=groups, bias=False,\n","    )\n","\n","\n","def conv1x1(in_channels, out_channels, stride=1):\n","    return nn.Conv2d(\n","        in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n","    )\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4  # 出力のチャンネル数を入力のチャンネル数の何倍に拡大するか\n","\n","    def __init__(self, in_channels, channels, stride=1, cardinality=1, base_width=64):\n","        super().__init__()\n","        width = int(channels * (base_width / 64)) * cardinality\n","        self.conv1 = conv1x1(in_channels, width)\n","        self.bn1 = nn.BatchNorm2d(width)\n","        self.conv2 = conv3x3(width, width, stride, groups=cardinality)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        self.conv3 = conv1x1(width, channels * self.expansion)\n","        self.bn3 = nn.BatchNorm2d(channels * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # 入力と出力のチャンネル数が異なる場合、x をダウンサンプリングする。\n","        if in_channels != channels * self.expansion:\n","            self.shortcut = nn.Sequential(\n","                conv1x1(in_channels, channels * self.expansion, stride),\n","                nn.BatchNorm2d(channels * self.expansion),\n","            )\n","        else:\n","            self.shortcut = nn.Sequential()\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        out += self.shortcut(x)\n","\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNeXt(nn.Module):\n","    def __init__(self, layers, num_classes=1000, cardinality=1, base_width=64):\n","        super().__init__()\n","\n","        self.in_channels = 64\n","        self.cardinality = cardinality\n","        self.base_width = base_width\n","        self.conv1 = nn.Conv2d(\n","            3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(64, layers[0])\n","        self.layer2 = self._make_layer(128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(512, layers[3], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n","\n","        # 重みを初期化する。\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, channels, blocks, stride=1):\n","        layers = []\n","\n","        layers.append(\n","            Bottleneck(\n","                self.in_channels,\n","                channels,\n","                stride,\n","                cardinality=self.cardinality,\n","                base_width=self.base_width,\n","            )\n","        )\n","\n","        self.in_channels = channels * Bottleneck.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                Bottleneck(\n","                    self.in_channels,\n","                    channels,\n","                    cardinality=self.cardinality,\n","                    base_width=self.base_width,\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","    \n","def resnext50_32x4d():\n","    return ResNeXt([3, 4, 6, 3], cardinality=32, base_width=4)\n","\n","model = resnext50_32x4d()"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T15:44:57.421411Z","iopub.status.busy":"2023-05-28T15:44:57.420983Z","iopub.status.idle":"2023-05-28T15:44:57.857308Z","shell.execute_reply":"2023-05-28T15:44:57.855109Z","shell.execute_reply.started":"2023-05-28T15:44:57.421379Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'train_test_split' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal train time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(elapced_time\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, elapced_time\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal best acc: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_acc))\n\u001b[0;32m---> 57\u001b[0m train, val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(train_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     58\u001b[0m traindataset \u001b[38;5;241m=\u001b[39m CassavaDataset(train, train_img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transform)\n\u001b[1;32m     59\u001b[0m valdataset \u001b[38;5;241m=\u001b[39m CassavaDataset(val, train_img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, transform)\n","\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"]}],"source":["def train_model(model, dt_dataloader, criterion, optimizer, epochs, device='cpu', sheduler=None):\n","    since = time.time()\n","    best_acc = 0.0\n","    \n","    if device == 'cuda':\n","        model = nn.DataParallel(model)\n","        torch.backends.cudnn.benchmark = True\n","    \n","    for epoch in range(epochs):\n","        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n","        print('-'*10)\n","        \n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            \n","            running_loss = 0.0\n","            running_corrects = 0.0\n","            \n","            for inputs, labels in tqdm(dt_dataloader[phase]):\n","                model = model.to(device)\n","                inputs = inputs.to(device)\n","                labels = labels.to(device) \n","                optimizer.zero_grad()\n","                \n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","                    \n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                    \n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds==labels)\n","                \n","            epoch_loss = running_loss / len(dt_dataloader[phase].dataset)\n","            epoch_acc = running_corrects / len(dt_dataloader[phase].dataset)\n","            \n","            if phase == 'val' and best_acc < epoch_acc:\n","                best_acc = epoch_acc\n","                torch.save(model.state_dict(), 'best_resnext.pth')\n","        \n","            if phase == 'train' and scheduler != None:\n","                scheduler.step()\n","            \n","            print('{} Loss: {:4f}, Acc: {:4f}'.format(phase, epoch_loss, epoch_acc))\n","        print()\n","    \n","    elapced_time = time.time() - since\n","    print(\"Total train time: {}m {}s\".format(elapced_time//60, elapced_time%60))\n","    print(\"Val best acc: {}\".format(best_acc))\n","    \n","train, val = train_test_split(train_df, test_size=0.2, random_state=42)\n","traindataset = CassavaDataset(train, train_img_path, 'train', transform)\n","valdataset = CassavaDataset(val, train_img_path, 'val', transform)\n","traindl = DataLoader(traindataset, batch_size=16, shuffle=True, num_workers=2)\n","valdl = DataLoader(valdataset, batch_size=16, shuffle=True, num_workers=2)\n","\n","dl_dict = {'train':traindl, 'val':valdl}\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)\n","epochs = 5\n","train_model(model, dl_dict, criterion, optimizer, epochs, device, scheduler)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test\n","model.load_state_dict(torch.load(os.path.join(data_path, 'baseline-resnext/best_resnext.pth')))\n","model.eval()\n","model = model.to(device)\n","\n","test_df = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n","testdataset = CassavaDataset(test_df, os.path.join(data_path, 'test_images'), 'test', transform)\n","testdl = DataLoader(testdataset, batch_size=1, shuffle=False, num_workers=2)\n","\n","predictions = []\n","for inputs in testdl:\n","    inputs = inputs.to(device)\n","    outputs = model(inputs)\n","    _, preds = torch.max(preds, 1)\n","    predictions.append(preds)\n","    \n","test_df['label'] = np.concatenate(predictions)\n","test_df.to_csv('submission.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
