{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ndata_path = \"../input/cassava-leaf-disease-classification\"\ntrain_img_path = os.path.join(data_path, \"train_images\")\ntrain_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA\nprint(\"Total Number of Train： {}\".format(len(train_df)))\nprint()\nprint(\"Each Ratio of Train data:\")\nprint(train_df['label'].value_counts()/len(train_df))\n(train_df['label'].value_counts()/len(train_df)).plot(kind='bar')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(df, data_img_path, figsize=(30,20)):\n    fig = plt.figure(figsize=figsize)\n    len_train = len(train_df[\"label\"].unique())\n    for i in range(len_train):\n        ax = fig.add_subplot(len_train, 1, i+1)\n        sample = df[df['label']==i]['image_id'].sample().reset_index(drop=True)\n        sample_img_path = os.path.join(data_img_path, sample.iloc[0])\n        img = cv2.imread(sample_img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        plt.title(\"Label: {}, Shape: {}\".format(i, img.shape))\n    \n    plt.show()\n    \nplot_images(train_df, train_img_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create Dataset and Transform\nclass CassavaDataset(Dataset):\n    def __init__(self, df:pd.DataFrame, data_img_path:str, phase:str='train', transform=None):\n        self.df = df\n        self.data_img_path = data_img_path\n        self.transform = transform\n        self.phase = phase\n        \n    def __getitem__(self, idx):\n        sample = self.df['image_id'].iloc[idx]\n        img = cv2.imread(os.path.join(self.data_img_path, sample))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            img = self.transform(img, self.phase)\n            \n        if self.phase=='test':\n            return img\n        \n        label = self.df['label'].iloc[idx]\n        \n        return img, label\n    \n    def __len__(self):\n        return len(self.df)\n    \nclass Transform(object):\n    def __init__(self, resize:int, mean:list, std:list, crop_size:int):\n        self.transform = {\n            'train':A.Compose([\n                A.Resize(resize, resize),\n                A.RandomCrop(height=crop_size, width=crop_size),\n                A.Normalize(mean, std),\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                ToTensorV2()\n            ]),\n            'val':A.Compose([\n                A.Resize(resize, resize),\n                A.CenterCrop(crop_size, crop_size),\n                A.Normalize(mean, std),\n                ToTensorV2()\n            ]),\n            'test':A.Compose([\n                A.Resize(resize, resize),\n                A.CenterCrop(crop_size, crop_size),\n                A.Normalize(mean, std),\n                ToTensorV2()\n            ]),\n        }\n    \n    def __call__(self, img, phase):\n        return self.transform[phase](image=img)['image']\n    \nresize = 256\ncrop_size = 224\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\ntransform = Transform(resize, mean, std, crop_size)\n\n# test dataset and transform\ndataset = CassavaDataset(train_df, train_img_path, 'train', transform)\ndataloader = DataLoader(dataset, shuffle=True, batch_size=1, num_workers=2)\niterator = dataloader.__iter__()\nimg, label = next(iterator)\nplt.imshow(img.numpy().transpose(2,3,1,0).reshape(crop_size, crop_size, 3))\nplt.title(\"Dataset and Transform Test, Label: {}\".format(label))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\ndef conv3x3(in_channels, out_channels, stride=1, groups=1):\n    return nn.Conv2d(\n        in_channels, out_channels, kernel_size=3, stride=stride, padding=1, groups=groups, bias=False,\n    )\n\n\ndef conv1x1(in_channels, out_channels, stride=1):\n    return nn.Conv2d(\n        in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n    )\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4  # 出力のチャンネル数を入力のチャンネル数の何倍に拡大するか\n\n    def __init__(self, in_channels, channels, stride=1, cardinality=1, base_width=64):\n        super().__init__()\n        width = int(channels * (base_width / 64)) * cardinality\n        self.conv1 = conv1x1(in_channels, width)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = conv3x3(width, width, stride, groups=cardinality)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = conv1x1(width, channels * self.expansion)\n        self.bn3 = nn.BatchNorm2d(channels * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n\n        # 入力と出力のチャンネル数が異なる場合、x をダウンサンプリングする。\n        if in_channels != channels * self.expansion:\n            self.shortcut = nn.Sequential(\n                conv1x1(in_channels, channels * self.expansion, stride),\n                nn.BatchNorm2d(channels * self.expansion),\n            )\n        else:\n            self.shortcut = nn.Sequential()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += self.shortcut(x)\n\n        out = self.relu(out)\n\n        return out\n\nclass ResNeXt(nn.Module):\n    def __init__(self, layers, num_classes=1000, cardinality=1, base_width=64):\n        super().__init__()\n\n        self.in_channels = 64\n        self.cardinality = cardinality\n        self.base_width = base_width\n        self.conv1 = nn.Conv2d(\n            3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(64, layers[0])\n        self.layer2 = self._make_layer(128, layers[1], stride=2)\n        self.layer3 = self._make_layer(256, layers[2], stride=2)\n        self.layer4 = self._make_layer(512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n\n        # 重みを初期化する。\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, channels, blocks, stride=1):\n        layers = []\n\n        layers.append(\n            Bottleneck(\n                self.in_channels,\n                channels,\n                stride,\n                cardinality=self.cardinality,\n                base_width=self.base_width,\n            )\n        )\n\n        self.in_channels = channels * Bottleneck.expansion\n        for _ in range(1, blocks):\n            layers.append(\n                Bottleneck(\n                    self.in_channels,\n                    channels,\n                    cardinality=self.cardinality,\n                    base_width=self.base_width,\n                )\n            )\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n    \ndef resnext50_32x4d():\n    return ResNeXt([3, 4, 6, 3], cardinality=32, base_width=4)\n\nmodel = resnext50_32x4d()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dt_dataloader, criterion, optimizer, epochs, device='cpu', sheduler=None):\n    since = time.time()\n    best_acc = 0.0\n    \n    if device == 'cuda':\n        model = nn.DataParallel(model)\n        torch.backends.cudnn.benchmark = True\n    \n    for epoch in range(epochs):\n        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n        print('-'*10)\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in tqdm(dt_dataloader[phase]):\n                model = model.to(device)\n                inputs = inputs.to(device)\n                labels = labels.to(device) \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds==labels)\n                \n            epoch_loss = running_loss / len(dt_dataloader[phase])\n            epoch_acc = running_corrects / len(dt_dataloader[phase])\n            \n            if phase == 'val' and best_acc < epoch_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), 'best_resnext.pth')\n        \n            if phase == 'train' and scheduler != None:\n                scheduler.step()\n            \n            print('{} Loss: {:4f}, Acc: {:4f}'.format(phase, epoch_loss, epoch_acc))\n        print()\n    \n    elapced_time = time.time() - since\n    print(\"Total train time: {}m {}s\".format(elapced_time//60, elapced_time%60))\n    print(\"Val best acc: {}\".format(best_acc))\n    \ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntraindataset = CassavaDataset(train, train_img_path, 'train', transform)\nvaldataset = CassavaDataset(val, train_img_path, 'val', transform)\ntraindl = DataLoader(traindataset, batch_size=16, shuffle=True, num_workers=2)\nvaldl = DataLoader(valdataset, batch_size=16, shuffle=True, num_workers=2)\n\ndl_dict = {'train':traindl, 'val':valdl}\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters())\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)\nepochs = 5\ntrain_model(model, dl_dict, criterion, optimizer, epochs, device, scheduler)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T15:44:57.420983Z","iopub.execute_input":"2023-05-28T15:44:57.421411Z","iopub.status.idle":"2023-05-28T15:44:57.857308Z","shell.execute_reply.started":"2023-05-28T15:44:57.421379Z","shell.execute_reply":"2023-05-28T15:44:57.855109Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal train time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(elapced_time\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, elapced_time\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal best acc: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_acc))\n\u001b[0;32m---> 57\u001b[0m train, val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(train_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     58\u001b[0m traindataset \u001b[38;5;241m=\u001b[39m CassavaDataset(train, train_img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transform)\n\u001b[1;32m     59\u001b[0m valdataset \u001b[38;5;241m=\u001b[39m CassavaDataset(val, train_img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, transform)\n","\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"],"ename":"NameError","evalue":"name 'train_test_split' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# test\nmodel.load_state_dict(torch.load(os.path.join(data_path, 'baseline-resnext/best_resnext.pth')))\nmodel.eval()\nmodel = model.to(device)\n\ntest_df = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\ntestdataset = CassavaDataset(test_df, os.path.join(data_path, 'test_images'), 'test', transform)\ntestdl = DataLoader(testdataset, batch_size=1, shuffle=False, num_workers=2)\n\npredictions = []\nfor inputs in testdl:\n    inputs = inputs.to(device)\n    outputs = model(inputs)\n    _, preds = torch.max(preds, 1)\n    predictions.append(preds)\n    \ntest_df['label'] = np.concatenate(predictions)\ntest_df.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]}]}